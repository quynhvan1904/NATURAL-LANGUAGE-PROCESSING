# -*- coding: utf-8 -*-
"""NLP | Source code.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15Z5jS-Of3eMimWO2KkxI1czXx0tLLsEe

link github: https://github.com/kimvo646/NLP.git

# Cài đặt

## pip install
"""

!pip install underthesea

!pip install gensim

!pip install tensorflow

"""## Thư viện"""

# Xử lý dữ liệu
import pandas as pd
import numpy as np
import string
import re
import nltk
from underthesea import sent_tokenize, word_tokenize
from itertools import chain
from collections import Counter
from joblib import load

# Trực quan hóa
import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib.ticker import MaxNLocator
from wordcloud import WordCloud

# Mô hình
## LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix
## RandomForest
from sklearn.ensemble import RandomForestClassifier
from joblib import dump
from sklearn.metrics import roc_curve, auc, roc_auc_score
from sklearn.preprocessing import label_binarize
## LSTM
import gensim
from gensim.models import Word2Vec
from tensorflow.keras.utils import to_categorical
from keras.models import Sequential
from keras.layers import LSTM, Dense, Dropout
from keras.callbacks import EarlyStopping
from tensorflow.keras.models import load_model

# Khác
import warnings
warnings.filterwarnings("ignore")

"""## input"""

link_train = 'https://raw.githubusercontent.com/kimvo646/NLP/main/train_data.csv'
train = pd.read_csv(link_train, sep='\t', encoding='utf-16')
train.head(10)

link_test = 'https://raw.githubusercontent.com/kimvo646/NLP/main/test_data.csv'
test = pd.read_csv(link_test, sep='\t', encoding='utf-16')
test.head()

link_valid = 'https://raw.githubusercontent.com/kimvo646/NLP/main/validation_data.csv'
valid = pd.read_csv(link_valid, sep='\t', encoding='utf-16')
valid.head()

"""# Tổng quan bộ dữ liệu"""

# Tổng số dòng, số cột của bộ dữ liệu
print ('Các cột hiện có của bộ dữ liệu:')
for x in train.columns:
  print('>', x)
print(f"Bộ dữ liệu bao gồm {train.shape[1]} cột và {train.shape[0]} dòng")

"""# Tiền xử lý

## Kiểm tra các giá trị bị thiếu
"""

train.info()

train.isna().sum()

"""## Tách từ"""

def normalize_text(s):
    # Uncased
    s = s.lower()

    # Remove punctuations
    s = ''.join(ch for ch in s if ch not in string.punctuation)

    # Remove entities
    s = re.sub(r'\b((\w+|)wzjwz\d+)\b', " ", s)

    # Remove numbers
    s = re.sub(r'\d', ' ', s)

     # Fix whitespaces
    s = re.sub(r'\s+', ' ', s)

    #Remove leading and trailing spaces
    s = s.strip()

    return s

def tokenizer(text):
    tokens = []
    for sent in sent_tokenize(text):
        words = word_tokenize(sent)
        tokens.extend(words)
    return tokens

"""## Biểu diễn dữ liệu"""

df_label = train.copy()

# Thay đổi giá trị trong cột 'sentiment' của bản sao
df_label['sentiment'] = df_label['sentiment'].replace({
    0: 'negative',
    1: 'positive'})

df_label['topic'] = df_label['topic'].replace({
    0: 'lecturer',
    1: 'training_program',
    2: 'facility',
    3: 'others'
})

# Tạo figure và axes
fig, axs = plt.subplots(1, 2, figsize=(10, 5))

# Vẽ biểu đồ pie cho cột 'sentiment'
df_label['sentiment'].value_counts().plot(kind='pie', ax=axs[0], autopct='%1.1f%%')
axs[0].set_title('Sentiment')

# Vẽ biểu đồ pie cho cột 'topic'
df_label['topic'].value_counts().plot(kind='pie', ax=axs[1], autopct='%1.1f%%')
axs[1].set_title('Topic')

# Hiển thị biểu đồ
plt.show()

# Tạo bảng tần số chéo giữa 'sentiment' và 'topic'
cross_tab = pd.crosstab(df_label['topic'], df_label['sentiment'])

# Vẽ barchart
cross_tab.plot(kind='bar', label = 'sentiment')
plt.xticks(rotation = 0)
plt.ylabel('Số lượng')
plt.xlabel('Topic')
plt.title('Số lượng Topic theo Sentiment')
plt.yscale('log')
plt.tight_layout()
plt.show()

"""##Text mining"""

train_x=train['sentence'].tolist()
train_x=[normalize_text(sentence)for sentence in train_x]
all_tokens_train = [tokenizer(sentence) for sentence in train_x]

valid_x = valid['sentence'].tolist()
valid_x=[normalize_text(sentence)for sentence in valid_x]
all_tokens_valid = [tokenizer(sentence) for sentence in valid_x]

test_x = test['sentence'].tolist()
test_x=[normalize_text(sentence)for sentence in test_x]
all_tokens_test = [tokenizer(sentence) for sentence in test_x]

#Đếm từ
all_tokens=list(chain.from_iterable(all_tokens_train))
counter=Counter(all_tokens)
# all_tokens

text = ' '.join(all_tokens)

# Tạo một đối tượng WordCloud
wordcloud = WordCloud(width = 500, height = 500,
                background_color ='white',
                stopwords = None,
                min_font_size = 10).generate(text)

# Vẽ WordCloud
plt.figure(figsize = (5, 5), facecolor = None)
plt.imshow(wordcloud)
plt.axis("off")
plt.tight_layout(pad = 0)

plt.show()

"""## Word2Vec
Nguồn tham khảo W2v: https://github.com/namlv97/biLSTM-vietnamese-uit-student-feedbacks/blob/main/biLSTM_Vietnamese_uit_student_feedbacks.ipynb
"""

# Cài đặt các chỉ số
min_count=1
window=3
vector_size=300
alpha=1e-3
min_alpha=1e-4
negative=10

word_sents_train=[sent for sent in all_tokens_train]
# Tạo mô hình Word2Vec
w2v_model = Word2Vec(min_count=min_count, window=window, vector_size=vector_size, alpha=alpha, min_alpha=min_alpha, negative=negative, sg=1)
# Xây dựng từ điển cho tập dữ liệu
w2v_model.build_vocab(word_sents_train)
#Huấn luyện mô hình
w2v_model.train(word_sents_train, total_examples=w2v_model.corpus_count, epochs=100, report_delay=1,compute_loss=True)

# Huấn luyện cho tập all_tokens_test
word_sents_test = [sent for sent in all_tokens_test]
w2v_model.build_vocab(word_sents_test, update=True)
w2v_model.train(word_sents_test, total_examples=w2v_model.corpus_count, epochs=100, report_delay=1, compute_loss=True)

# Huấn luyện cho tập all_tokens_valid
word_sents_valid = [sent for sent in all_tokens_valid]
w2v_model.build_vocab(word_sents_valid, update=True)
w2v_model.train(word_sents_valid, total_examples=w2v_model.corpus_count, epochs=100, report_delay=1, compute_loss=True)

# Lưu mô hình sau khi huấn luyện
w2v_model.save("model_w2v")

"""# Huấn luyện mô hình

##Random Forest
"""

def sentence_to_vec(sentence, model):
    vecs = [model.wv[word] for word in sentence if word in model.wv]
    if vecs:
        return np.mean(vecs, axis=0)
    else:
        return np.zeros(model.vector_size)

"""###Topic"""

train_y=train['topic'].tolist()
test_y = test['topic'].tolist()

# Tạo ma trận đặc trưng cho tập huấn luyện và kiểm tra
X_train_w2v = np.array([sentence_to_vec(sent, w2v_model) for sent in word_sents_train])
X_test_w2v = np.array([sentence_to_vec(sent, w2v_model) for sent in word_sents_test])

# Tạo mô hình Decision Tree
classifier_topic = RandomForestClassifier(random_state=42)

# Huấn luyện mô hình với dữ liệu huấn luyện Word2Vec
classifier_topic.fit(X_train_w2v, train_y)

# Lưu mô hình
dump(classifier_topic, 'model_random_forest_topic.joblib')

# Dự đoán với dữ liệu kiểm tra
predicted_y = classifier_topic.predict(X_test_w2v)

# Tính toán các chỉ số đánh giá
accuracy = accuracy_score(test_y, predicted_y)
recall = recall_score(test_y, predicted_y, average='weighted')
precision = precision_score(test_y, predicted_y, average='weighted')
f1 = f1_score(test_y, predicted_y, average='weighted')

# In ra các chỉ số
print(f'Accuracy: {accuracy}')
print(f'Recall:   {recall}')
print(f'Precision: {precision}')
print(f'F1 Score: {f1}')

# Tạo và in ra ma trận nhầm lẫn
conf_mat = confusion_matrix(test_y, predicted_y)

# Tính tổng số lượng mẫu thực tế cho mỗi lớp
row_sums = conf_mat.sum(axis=1)

# Chuẩn hóa ma trận nhầm lẫn bằng cách chia cho tổng số lượng mẫu thực tế
norm_conf_mat = conf_mat / row_sums[:, np.newaxis]

# Tạo nhãn cho mỗi ô
labels = [f'{val:.2f}' for val in norm_conf_mat.flatten()]
labels = np.asarray(labels).reshape(norm_conf_mat.shape)

# Vẽ ma trận nhầm lẫn đã chuẩn hóa
plt.figure(figsize=(5,4))
sns.heatmap(norm_conf_mat, annot=labels, fmt='', cmap='Blues')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Random Forest Confusion Matrix For Topic')
plt.show()

# Binarize the output
train_y_bin = label_binarize(train_y, classes=np.unique(train_y))
test_y_bin = label_binarize(test_y, classes=np.unique(train_y))

# Compute the predicted probabilities
predicted_probs = classifier_topic.predict_proba(X_test_w2v)

# Compute ROC curve and ROC area for each class
fpr = dict()
tpr = dict()
roc_auc = dict()
n_classes = len(np.unique(train_y))
for i in range(n_classes):
    fpr[i], tpr[i], _ = roc_curve(test_y_bin[:, i], predicted_probs[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])

# Plot all ROC curves
plt.figure()
for i in range(n_classes):
    plt.plot(fpr[i], tpr[i], label='ROC curve of class {0} (area = {1:0.2f})'.format(i, roc_auc[i]))
plt.plot([0, 1], [0, 1], 'k--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Random Forest ROC')
plt.legend(loc="lower right")
plt.show()

# Compute Macro-average AUC
macro_auc = roc_auc_score(test_y_bin, predicted_probs, multi_class='ovr', average='macro')
print('Macro-average AUC:', macro_auc)

# Compute Micro-average AUC
micro_auc = roc_auc_score(test_y_bin, predicted_probs, multi_class='ovr', average='micro')
print('Micro-average AUC:', micro_auc)

"""###Sentiment"""

train_y=train['sentiment'].tolist()
test_y = test['sentiment'].tolist()

# Tạo ma trận đặc trưng cho tập huấn luyện và kiểm tra
X_train_w2v = np.array([sentence_to_vec(sent, w2v_model) for sent in word_sents_train])
X_test_w2v = np.array([sentence_to_vec(sent, w2v_model) for sent in word_sents_test])

# Tạo mô hình Random Forest
classifier_sentiment = RandomForestClassifier(random_state=42)

# Huấn luyện mô hình với dữ liệu huấn luyện Word2Vec
classifier_sentiment.fit(X_train_w2v, train_y)

# Lưu mô hình
dump(classifier_sentiment, 'model_random_forest_sentiment.joblib')

# Dự đoán với dữ liệu kiểm tra
predicted_y = classifier_sentiment.predict(X_test_w2v)

# Tính toán các chỉ số đánh giá
accuracy = accuracy_score(test_y, predicted_y)
recall = recall_score(test_y, predicted_y, average='weighted')
precision = precision_score(test_y, predicted_y, average='weighted')
f1 = f1_score(test_y, predicted_y, average='weighted')

# In ra các chỉ số
print(f'Accuracy: {accuracy}')
print(f'Recall:   {recall}')
print(f'Precision: {precision}')
print(f'F1 Score: {f1}')

# Tạo và in ra ma trận nhầm lẫn
conf_mat = confusion_matrix(test_y, predicted_y)

# Tính tổng số lượng mẫu thực tế cho mỗi lớp
row_sums = conf_mat.sum(axis=1)

# Chuẩn hóa ma trận nhầm lẫn bằng cách chia cho tổng số lượng mẫu thực tế
norm_conf_mat = conf_mat / row_sums[:, np.newaxis]

# Tạo nhãn cho mỗi ô
labels = [f'{val:.2f}' for val in norm_conf_mat.flatten()]
labels = np.asarray(labels).reshape(norm_conf_mat.shape)

# Vẽ ma trận nhầm lẫn đã chuẩn hóa
plt.figure(figsize=(5,4))
sns.heatmap(norm_conf_mat, annot=labels, fmt='', cmap='Blues')
plt.xlabel('Predicted Sentiment')
plt.ylabel('Actual Sentiment')
plt.title('Random Forest Confusion Matrix For Sentiment')
plt.show()

"""##Logistic Regression

### Topic
"""

def get_sentence_vector(sentence, model):
    vector_sum = np.zeros(model.vector_size)
    count = 0
    for word in sentence:
        if word in model.wv:
            vector_sum += model.wv[word]
            count += 1
    if count != 0:
        return vector_sum / count
    else:
        return vector_sum

X_train_w2v = [get_sentence_vector(sentence, w2v_model) for sentence in all_tokens_train]
X_test_w2v = [get_sentence_vector(sentence, w2v_model) for sentence in all_tokens_test]

# Chia dữ liệu thành features và labels
X_train_w2v = np.array(X_train_w2v)
X_test_w2v = np.array(X_test_w2v)

y_train_topic = train['topic']
y_test_topic = test['topic']

logistic_model_topic = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=100, random_state=42)
logistic_model_topic.fit(X_train_w2v, train['topic'])
pred_topic = logistic_model_topic.predict(X_test_w2v)

dump(logistic_model_topic, 'model_Logistic_Regression_topic.joblib')

accuracy = accuracy_score(y_test_topic, pred_topic)
precision = precision_score(y_test_topic, pred_topic, average='weighted')
recall = recall_score(y_test_topic, pred_topic, average='weighted')
f1 = f1_score(y_test_topic, pred_topic, average='weighted')
print(f'Accuracy: {accuracy}')
print(f'Precision: {precision}')
print(f'Recall: {recall}')
print(f'F1 Score: {f1}')

conf_mat = confusion_matrix(y_test_topic, pred_topic)

# Tính tổng số lượng mẫu thực tế cho mỗi lớp
row_sums = conf_mat.sum(axis=1)

# Chuẩn hóa ma trận nhầm lẫn bằng cách chia cho tổng số lượng mẫu thực tế
norm_conf_mat = conf_mat / row_sums[:, np.newaxis]

# Tạo nhãn cho mỗi ô
labels = [f'{val:.2f}' for val in norm_conf_mat.flatten()]
labels = np.asarray(labels).reshape(norm_conf_mat.shape)

# Vẽ ma trận nhầm lẫn đã chuẩn hóa
plt.figure(figsize=(5,4))
sns.heatmap(norm_conf_mat, annot=labels, fmt='', cmap='Blues')
plt.title('Logistic Regression Confusion Matrix For Topic')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

"""### Sentiment"""

X_train_w2v = [get_sentence_vector(sentence, w2v_model) for sentence in all_tokens_train]
X_test_w2v = [get_sentence_vector(sentence, w2v_model) for sentence in all_tokens_test]

# Chia dữ liệu thành features và labels
X_train_w2v = np.array(X_train_w2v)
X_test_w2v = np.array(X_test_w2v)
# Chia dữ liệu thành features và labels cho topic
y_train_sentiment = train['sentiment']
y_test_sentiment = test['sentiment']

logistic_model_sentiment = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=100, random_state=42)
logistic_model_sentiment.fit(X_train_w2v, train['sentiment'])
pred_sentiment = logistic_model_sentiment.predict(X_test_w2v)

dump(logistic_model_sentiment, 'model_Logistic_Regression_sentiment.joblib')

accuracy = accuracy_score(y_test_sentiment, pred_sentiment)
precision = precision_score(y_test_sentiment, pred_sentiment, average='weighted')
recall = recall_score(y_test_sentiment, pred_sentiment, average='weighted')
f1 = f1_score(y_test_sentiment, pred_sentiment, average='weighted')
print(f'Accuracy: {accuracy}')
print(f'Precision: {precision}')
print(f'Recall: {recall}')
print(f'F1 Score: {f1}')

conf_mat = confusion_matrix(y_test_sentiment, pred_sentiment)

# Tính tổng số lượng mẫu thực tế cho mỗi lớp
row_sums = conf_mat.sum(axis=1)

# Chuẩn hóa ma trận nhầm lẫn bằng cách chia cho tổng số lượng mẫu thực tế
norm_conf_mat = conf_mat / row_sums[:, np.newaxis]

# Tạo nhãn cho mỗi ô
labels = [f'{val:.2f}' for val in norm_conf_mat.flatten()]
labels = np.asarray(labels).reshape(norm_conf_mat.shape)

# Vẽ ma trận nhầm lẫn đã chuẩn hóa
plt.figure(figsize=(5,4))
sns.heatmap(norm_conf_mat, annot=labels, fmt='', cmap='Blues')
plt.title('Logistic Regression Confusion Matrix For Sentiment')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

"""## LSTM

### Topic
"""

# # Kích thước của từ điển
# vocab_size = len(w2v_model.wv.key_to_index) + 1

# Kích thước của vector nhúng
embedding_dim = w2v_model.vector_size

# Xây dựng mô hình LSTM
model_LSTM_topic = Sequential()
model_LSTM_topic.add(LSTM(units=100, return_sequences=True, input_shape=(1, embedding_dim)))
model_LSTM_topic.add(Dropout(0.2))
model_LSTM_topic.add(LSTM(units=50, return_sequences=True))
model_LSTM_topic.add(Dropout(0.2))
model_LSTM_topic.add(LSTM(units=50, return_sequences=True))
model_LSTM_topic.add(Dropout(0.2))
model_LSTM_topic.add(LSTM(units=50))
model_LSTM_topic.add(Dropout(0.2))
model_LSTM_topic.add(Dense(units=4, activation="softmax"))

# Biên dịch mô hình
model_LSTM_topic.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

print(model_LSTM_topic.summary())

def get_vector(word_list, model):
    # Khởi tạo một vector 0
    vec = np.zeros(model.vector_size).reshape((1, model.vector_size))
    count = 0.
    for word in word_list:
        # Thêm vector của từ vào vec
        vec += model.wv.get_vector(word).reshape((1, model.vector_size))
        count += 1.
    if count != 0:
        vec /= count
    return vec

X_train = np.concatenate([get_vector(sent, w2v_model) for sent in all_tokens_train])
X_valid = np.concatenate([get_vector(sent, w2v_model) for sent in all_tokens_valid])

#xác định các tập để huấn luyện mô hình
y_train = to_categorical(train['topic'])

X_train = X_train.reshape(-1, 1, embedding_dim)
X_valid = X_valid.reshape(-1, 1, embedding_dim)

# Huấn luyện mô hình
model_LSTM_topic.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_valid, to_categorical(valid['topic'])))

model_LSTM_topic.save('model_LSTM_topic.h5')

# Tạo vector nhúng cho dữ liệu kiểm tra
X_test = np.concatenate([get_vector(sent, w2v_model) for sent in all_tokens_test])
X_test = X_test.reshape(-1, 1, embedding_dim)

# Dự đoán nhãn cho dữ liệu kiểm tra
y_pred = model_LSTM_topic.predict(X_test)
y_pred = np.argmax(y_pred, axis=1)  # Chuyển từ dạng one-hot về dạng nhãn

# Chuyển nhãn thực tế sang dạng số
y_true = test['topic'].values

# Tính toán các chỉ số
accuracy = accuracy_score(y_true, y_pred)
recall = recall_score(y_true, y_pred, average='macro')
precision = precision_score(y_true, y_pred, average='macro')
f1 = f1_score(y_true, y_pred, average='macro')

print(f"Accuracy: {accuracy}")
print(f"Recall: {recall}")
print(f"Precision: {precision}")
print(f"F1 Score: {f1}")

# Tạo và in ra confusion matrix
conf_mat = confusion_matrix(y_true, y_pred)

# Tính tổng số lượng mẫu thực tế cho mỗi lớp
row_sums = conf_mat.sum(axis=1)

# Chuẩn hóa ma trận nhầm lẫn bằng cách chia cho tổng số lượng mẫu thực tế
norm_conf_mat = conf_mat / row_sums[:, np.newaxis]

# Tạo nhãn cho mỗi ô
labels = [f'{val:.2f}' for val in norm_conf_mat.flatten()]
labels = np.asarray(labels).reshape(norm_conf_mat.shape)

# Vẽ ma trận nhầm lẫn đã chuẩn hóa
plt.figure(figsize=(5,4))
sns.heatmap(norm_conf_mat, annot=labels, fmt='', cmap='Blues')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('LSTM Confusion Matrix For Topic')
plt.show()

"""### Sentiment"""

# Xây dựng mô hình LSTM
model_LSTM_sentiment = Sequential()
model_LSTM_sentiment.add(LSTM(units=100, return_sequences=True, input_shape=(1, embedding_dim)))
model_LSTM_sentiment.add(Dropout(0.2))
model_LSTM_sentiment.add(LSTM(units=50, return_sequences=True))
model_LSTM_sentiment.add(Dropout(0.2))
model_LSTM_sentiment.add(LSTM(units=50, return_sequences=True))
model_LSTM_sentiment.add(Dropout(0.2))
model_LSTM_sentiment.add(LSTM(units=50))
model_LSTM_sentiment.add(Dropout(0.2))
model_LSTM_sentiment.add(Dense(units=2, activation="softmax"))

# Biên dịch mô hình
model_LSTM_sentiment.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

print(model_LSTM_sentiment.summary())

#xác định các tập để huấn luyện mô hình
y_train = to_categorical(train['sentiment'])

# Huấn luyện mô hình
early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)
model_LSTM_sentiment.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_valid, to_categorical(valid['sentiment'])), callbacks=[early_stopping])

model_LSTM_sentiment.save('model_LSTM_sentiment.h5')

# Tạo vector nhúng cho dữ liệu kiểm tra
X_test = np.concatenate([get_vector(sent, w2v_model) for sent in all_tokens_test])
X_test = X_test.reshape(-1, 1, embedding_dim)

# Dự đoán nhãn cho dữ liệu kiểm tra
y_pred = model_LSTM_sentiment.predict(X_test)
y_pred = np.argmax(y_pred, axis=1)  # Chuyển từ dạng one-hot về dạng nhãn

# Chuyển nhãn thực tế sang dạng số
y_true = test['sentiment'].values

# Tính toán các chỉ số
accuracy = accuracy_score(y_true, y_pred)
recall = recall_score(y_true, y_pred, average='macro')
precision = precision_score(y_true, y_pred, average='macro')
f1 = f1_score(y_true, y_pred, average='macro')

print(f"Accuracy: {accuracy}")
print(f"Recall: {recall}")
print(f"Precision: {precision}")
print(f"F1 Score: {f1}")

# Tạo và in ra ma trận nhầm lẫn
conf_mat = confusion_matrix(y_true, y_pred)

# Tính tổng số lượng mẫu thực tế cho mỗi lớp
row_sums = conf_mat.sum(axis=1)

# Chuẩn hóa ma trận nhầm lẫn bằng cách chia cho tổng số lượng mẫu thực tế
norm_conf_mat = conf_mat / row_sums[:, np.newaxis]

# Tạo nhãn cho mỗi ô
labels = [f'{val:.2f}' for val in norm_conf_mat.flatten()]
labels = np.asarray(labels).reshape(norm_conf_mat.shape)

# Vẽ ma trận nhầm lẫn đã chuẩn hóa
plt.figure(figsize=(5,4))
sns.heatmap(norm_conf_mat, annot=labels, fmt='', cmap='Blues')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('LSTM Confusion Matrix For Sentiment')
plt.show()

"""# Dự đoán"""

def preprocess_and_embed(text, w2v_model):
    # Tiền xử lý văn bản
    normalized_text = normalize_text(text)
    tokenized_text = tokenizer(normalized_text)
    # Tạo vector nhúng cho văn bản
    vector = get_vector(tokenized_text, w2v_model)
    vector = vector.reshape(-1, 1, w2v_model.vector_size)
    return tokenized_text, vector

def predict_topic(sentence, w2v_model, lstm_model=None, rf_model=None, lr_model=None):
    # Tiền xử lý và tạo vector nhúng
    tokenized_text, embedding = preprocess_and_embed(sentence, w2v_model)

    if lstm_model:
        # Dự đoán topic bằng LSTM
        prediction = lstm_model.predict(embedding)
        topic_labels = ['lecturer', 'training_program', 'facility', 'others']
        predicted_topic = topic_labels[np.argmax(prediction)]
        return predicted_topic

    elif rf_model:
        # Dự đoán topic bằng Random Forest
        prediction = rf_model.predict([embedding.flatten()])
        topic_labels = ['lecturer', 'training_program', 'facility', 'others']
        predicted_topic = topic_labels[prediction[0]]
        return predicted_topic

    elif lr_model:
        # Dự đoán topic bằng Logistic Regression
        prediction = lr_model.predict([embedding.flatten()])
        topic_labels = ['lecturer', 'training_program', 'facility', 'others']
        predicted_topic = topic_labels[prediction[0]]
        return predicted_topic

def predict_sentiment(sentence, w2v_model, lstm_model=None, rf_model=None, lr_model=None):
    # Tiền xử lý và tạo vector nhúng
    tokenized_text, embedding = preprocess_and_embed(sentence, w2v_model)

    if lstm_model:
        # Dự đoán sentiment bằng LSTM
        prediction = lstm_model.predict(embedding)
        sentiment_labels = ['negative', 'positive']
        predicted_sentiment = sentiment_labels[np.argmax(prediction)]
        return predicted_sentiment

    elif rf_model:
        # Dự đoán sentiment bằng Random Forest
        prediction = rf_model.predict([embedding.flatten()])
        sentiment_labels = ['negative', 'positive']
        predicted_sentiment = sentiment_labels[prediction[0]]
        return predicted_sentiment

    elif lr_model:
        # Dự đoán sentiment bằng Logistic Regression
        prediction = lr_model.predict([embedding.flatten()])
        sentiment_labels = ['negative', 'positive']
        predicted_sentiment = sentiment_labels[prediction[0]]
        return predicted_sentiment

"""## Topic"""

text_to_predict = input("Nhập đoạn văn bản cần dự đoán: ")

predicted_topic_lr = predict_topic(text_to_predict, w2v_model, lr_model=logistic_model_topic)
predicted_topic_lstm = predict_topic(text_to_predict, w2v_model, lstm_model=model_LSTM_topic)
predicted_topic_rf = predict_topic(text_to_predict, w2v_model, rf_model=classifier_topic)

print(f"Random Forest - Dự đoán Topic: {predicted_topic_rf}")
print(f"Logistic Regression - Dự đoán Topic: {predicted_topic_lr}")
print(f"LSTM - Dự đoán Topic: {predicted_topic_lstm}")

"""## Sentiment"""

predicted_sentiment_rf = predict_sentiment(text_to_predict, w2v_model, rf_model=classifier_sentiment)
predicted_sentiment_lr = predict_sentiment(text_to_predict, w2v_model, lr_model=logistic_model_sentiment)
predicted_sentiment_lstm = predict_sentiment(text_to_predict, w2v_model, lstm_model=model_LSTM_sentiment)

print(f"Random Forest - Dự đoán Sentiment: {predicted_sentiment_rf}")
print(f"Logistic Regression - Dự đoán Sentiment: {predicted_sentiment_lr}")
print(f"LSTM - Dự đoán Sentiment: {predicted_sentiment_lstm}")